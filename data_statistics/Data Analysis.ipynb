{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1432d6e-4517-475d-a62a-90790aebb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import stanza\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26737f-88c4-4ed1-a9cd-1e1a4349a90a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d311177a-67a1-4454-98f0-6554017f0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('drop_dataset_train.json') as json_file:\n",
    "    train_data = json.load(json_file)\n",
    "with open('drop_dataset_dev.json') as json_file:\n",
    "    dev_data = json.load(json_file)\n",
    "dataset = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79efc95-7239-448b-8aaf-8da90a1e0d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasize: 5565\n"
     ]
    }
   ],
   "source": [
    "print('Datasize: {s}'.format(s=len(dataset.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccfeff62-0e7b-4ab1-8baa-48db24b0b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_text = {}\n",
    "question_answer_text ={}\n",
    "passage_type = {}\n",
    "question_answer_type ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c2780-f56e-4788-a3f6-216e5cb27309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e8548-e4b2-4fef-8fbe-e380ec356de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a9939c3-e189-4f9c-8775-10f58efbd911",
   "metadata": {},
   "source": [
    "# CoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c5e85a-9baf-4642-b6c0-3ace98e3f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model = stanza.Pipeline(logging_level = 'FATAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb37c8f-b85b-4a11-bd4f-53b9aa1ed80b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945c9f73-92bf-42dd-a08e-ce465b7de145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Progress]:[████████████████████]100.00%;"
     ]
    }
   ],
   "source": [
    "temp = 0\n",
    "total = len(dataset.keys())\n",
    "ex_list =[]\n",
    "for key,item in dataset.items():\n",
    "    try:\n",
    "        doc = nlp_model(item['passage'])\n",
    "        passage_text[key] = [x.text for x in doc.ents]\n",
    "        passage_type[key] = [(x.text,x.type) for x in doc.ents]\n",
    "    \n",
    "        question_answer_text[key] = []\n",
    "        question_answer_type[key] = []\n",
    "        for q in item[\"qa_pairs\"]:\n",
    "            q_text = {} \n",
    "            q_type = {} \n",
    "            doc = nlp_model( q[\"question\"])\n",
    "            q_text[\"question\"] = [x.text for x in doc.ents]\n",
    "            q_type[\"question\"] = [(x.text,x.type) for x in doc.ents]\n",
    "            if len(q[\"answer\"][\"number\"])!= 0:\n",
    "                q_text[\"answer\"] = q[\"answer\"][\"number\"]\n",
    "                q_type[\"answer\"] = [(q[\"answer\"][\"number\"],\"number\")] \n",
    "            elif len(q[\"answer\"][\"spans\"])!= 0:\n",
    "                q_text[\"answer\"] =[]\n",
    "                q_type[\"answer\"] =[]\n",
    "                for anw in q[\"answer\"][\"spans\"]:\n",
    "                    doc = nlp_model(anw)\n",
    "                    q_text[\"answer\"].append([x.text for x in doc.ents])\n",
    "                    q_type[\"answer\"].append([(x.text,x.type) for x in doc.ents])\n",
    "            else:\n",
    "                q_text[\"answer\"] =q[\"answer\"][\"date\"]\n",
    "                q_type[\"answer\"] =[(q[\"answer\"][\"date\"],\"date\")]\n",
    "            question_answer_text[key].append(q_text)\n",
    "            question_answer_type[key].append(q_type)    \n",
    "        temp += 1\n",
    "        print('\\r' + '[Progress]:[%s%s]%.2f%%;' % ('█' * int(temp*20/total), ' ' * (20-int(temp*20/total)),float(temp/total*100)), end='')\n",
    "        if temp%100 == 1:\n",
    "            with open('passage_text.json', 'w') as fp:\n",
    "                json.dump(passage_text, fp)\n",
    "            with open('passage_type.json', 'w') as fp:\n",
    "                json.dump(passage_type, fp)\n",
    "            with open('question_answer_text.json', 'w') as fp:\n",
    "                json.dump(question_answer_text, fp)\n",
    "            with open('question_answer_type.json', 'w') as fp:\n",
    "                json.dump(question_answer_type, fp)  \n",
    "    except:\n",
    "        temp += 1\n",
    "        pass    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e91842-a74f-4168-8b8c-e80f83a3b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('passage_text.json', 'w') as fp:\n",
    "    json.dump(passage_text, fp)\n",
    "with open('passage_type.json', 'w') as fp:\n",
    "    json.dump(passage_type, fp) \n",
    "with open('question_answer_text.json', 'w') as fp:\n",
    "    json.dump(question_answer_text, fp)\n",
    "with open('question_answer_type.json', 'w') as fp:\n",
    "    json.dump(question_answer_type, fp)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145ab13-426d-445d-a31b-a4ef06405fd6",
   "metadata": {},
   "source": [
    "# Output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f8ce7-df10-4c9e-a0f9-8baefd682f94",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Passage</summary>\n",
    "  \n",
    "  * Passage_text(dict)  \n",
    "      * KEY: passage key(list):\n",
    "          * passage word (from CoreNLP)(str):\n",
    "  * Passage_type(dict)  \n",
    "      * KEY: passage key(list):\n",
    "          * (passage word,type)(tuple):\n",
    "</details>\n",
    "<details>\n",
    "  <summary>Question_Answer</summary>\n",
    "  \n",
    "  * question_answer_text(dict)  \n",
    "      * KEY: passage key(list):\n",
    "          * question and answer(dict):\n",
    "              * KEY: question(list):\n",
    "                  * word (from CoreNLP)(str): \n",
    "              * KEY: answer(list):\n",
    "                  * answer, different types have different formates:\n",
    "                      * number,date same as original dictionary\n",
    "                      * spans(list):\n",
    "                          * single span(list):\n",
    "                              * word (from CoreNLP)(str)\n",
    "  * question_answer_type(dict)  \n",
    "      * KEY: passage key(list):\n",
    "          * question and answer(dict):\n",
    "              * KEY:  question(list):\n",
    "                  * words (from CoreNLP)(str): \n",
    "              * KEY: answer(list):\n",
    "                  * answer, different types have different formates:\n",
    "                      * number,date same as original dictionary: (answer(original original dictionary),type)(tuple)\n",
    "                      * spans(list):\n",
    "                          * single span(list):\n",
    "                              * (word,type)(str)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8719c7f-9f52-45bd-9b60-2681fd240fb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653be54d-26e3-4af0-a85f-a280499942c2",
   "metadata": {},
   "source": [
    "\n",
    "count = 0\n",
    "for key,item in dataset.items():\n",
    "    doc = nlp_model(item['passage'])\n",
    "    passage_text[key] = [x.text for x in doc.ents]\n",
    "    passage_type[key] = [(x.text,x.type) for x in doc.ents]\n",
    "    \n",
    "    question_answer_text[key] = []\n",
    "    question_answer_type[key] = []\n",
    "    for q in item[\"qa_pairs\"]:\n",
    "        q_text = {} \n",
    "        q_type = {} \n",
    "        doc = nlp_model( q[\"question\"])\n",
    "        q_text[\"question\"] = [x.text for x in doc.ents]\n",
    "        q_type[\"question\"] = [(x.text,x.type) for x in doc.ents]\n",
    "        if len(q[\"answer\"][\"number\"])!= 0:\n",
    "            q_text[\"answer\"] = q[\"answer\"][\"number\"]\n",
    "            q_type[\"answer\"] = [(q[\"answer\"][\"number\"],\"number\")] \n",
    "        elif len(q[\"answer\"][\"spans\"])!= 0:\n",
    "            q_text[\"answer\"] =[]\n",
    "            q_type[\"answer\"] =[]\n",
    "            for anw in q[\"answer\"][\"spans\"]:\n",
    "                doc = nlp_model(anw)\n",
    "                q_text[\"answer\"].append([x.text for x in doc.ents])\n",
    "                q_type[\"answer\"].append([(x.text,x.type) for x in doc.ents])\n",
    "        else:\n",
    "            q_text[\"answer\"] =q[\"answer\"][\"date\"]\n",
    "            q_type[\"answer\"] =[(q[\"answer\"][\"date\"],\"date\")]\n",
    "        question_answer_text[key].append(q_text)\n",
    "        question_answer_type[key].append(q_type)    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
